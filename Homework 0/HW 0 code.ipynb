{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzTlscCtLn5m",
        "outputId": "a7ad1a32-07c6-4099-a87d-9c8fd657553c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from collections import Counter\n",
        "from nltk.stem.porter import *\n",
        "import json\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SAMPLE CODE FOR GENERATING THE UNIGRAMS\n",
        "\n",
        "# stemming tool from nltk\n",
        "stemmer = PorterStemmer()\n",
        "# a mapping dictionary that help remove punctuations\n",
        "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
        "def get_tokens(text):\n",
        "  # turn document into lowercase\n",
        "  lowers = text.lower()\n",
        "  # remove punctuations\n",
        "  no_punctuation = lowers.translate(remove_punctuation_map)\n",
        "  # tokenize document\n",
        "  tokens = nltk.word_tokenize(no_punctuation)\n",
        "  # remove stop words\n",
        "  filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
        "  # stemming process\n",
        "  stemmed = []\n",
        "  for item in filtered:\n",
        "    if stemmer.stem(item) in predefined_unigrams:\n",
        "      stemmed.append(stemmer.stem(item))\n",
        "  # final unigrams\n",
        "  return stemmed"
      ],
      "metadata": {
        "id": "HNptXCGrMP8Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_path = '/content/drive/MyDrive/dictionary.txt'  # Path for Dictionary file (dictionary.txt)\n",
        "data_path = '/content/drive/MyDrive/24_train_1.csv'  # Path for Dataset file (24_train_1.csv)"
      ],
      "metadata": {
        "id": "l87Tm0O7NpTM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#READING THE CSV FILE\n",
        "data = pd.read_csv(data_path)\n",
        "print(data)\n",
        "output_Doc = data['ArticleId']\n",
        "# print(output_Doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddQqaw7_PfLE",
        "outputId": "c5e2a46d-3478-4bc3-9c92-b9685c95f367"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ArticleId                                               Text  \\\n",
            "0         1429  sfa awaits report over mikoliunas the scottish...   \n",
            "1         1896  parmalat to return to stockmarket parmalat  th...   \n",
            "2         1633  edu blasts arsenal arsenal s brazilian midfiel...   \n",
            "3         2178  henman decides to quit davis cup tim henman ha...   \n",
            "4          194  french suitor holds lse meeting european stock...   \n",
            "..         ...                                                ...   \n",
            "995       1250  blair  damaged  by blunkett row a majority of ...   \n",
            "996       1639  a november to remember last saturday  one news...   \n",
            "997        916  highbury tunnel players in clear the football ...   \n",
            "998       2217  top stars join us tsunami tv show brad pitt  r...   \n",
            "999        902  eastwood s baby scoops top oscars clint eastwo...   \n",
            "\n",
            "          Category  \n",
            "0            sport  \n",
            "1         business  \n",
            "2            sport  \n",
            "3            sport  \n",
            "4         business  \n",
            "..             ...  \n",
            "995       politics  \n",
            "996          sport  \n",
            "997          sport  \n",
            "998  entertainment  \n",
            "999  entertainment  \n",
            "\n",
            "[1000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#open the file located in dict_path and read it.\n",
        "with open(dict_path, 'r') as file:\n",
        "    predefined_unigrams = set(file.read().splitlines()) #split the lines\n",
        "\n",
        "with open(dict_path, 'r') as file:\n",
        "    ordered_words = file.read().splitlines() #split the lines\n"
      ],
      "metadata": {
        "id": "W5jDbSh-Pj4L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take the 'Text' column and pass it to the get_tokens function for generating unigrams for each article\n",
        "processed_docs = [get_tokens(articles) for articles in data['Text']]\n",
        "#processed_docs is a list of all the articles in the unigram format"
      ],
      "metadata": {
        "id": "ymzhrwFvPyX0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_dicts = []\n",
        "for doc in processed_docs:\n",
        "    word_count = dict(Counter(doc))\n",
        "    word_dicts.append(word_count)\n",
        "# print(word_dicts)"
      ],
      "metadata": {
        "id": "kIaB1xy_Y_MF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the frequency of each term in each document\n",
        "def compute_term_frequencies(docs):\n",
        "    frequencies = []\n",
        "    for doc in docs:\n",
        "        # Process the document to get filtered unigrams\n",
        "        terms = get_tokens(doc)\n",
        "        frequencies.append(Counter(terms))\n",
        "    return frequencies"
      ],
      "metadata": {
        "id": "LhelwUvPbHrK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to calculate TFIFD\n",
        "def compute_tf_idf(docs, dictionary):\n",
        "    # Initialize matrices\n",
        "    tf = np.zeros((len(docs), len(dictionary)), dtype=np.float64)\n",
        "    idf = np.zeros(len(dictionary), dtype=np.float64)\n",
        "\n",
        "    # Term frequencies\n",
        "    term_freqs = compute_term_frequencies(docs)\n",
        "\n",
        "    # Calculate TF and IDF\n",
        "    for i, doc_freqs in enumerate(term_freqs):\n",
        "        max_freq = max(doc_freqs.values(), default=1)\n",
        "        for j, term in enumerate(dictionary):\n",
        "            tf[i, j] = doc_freqs[term] / max_freq if term in doc_freqs else 0\n",
        "            if i == 0:\n",
        "                n_containing_term = sum(term in doc for doc in term_freqs)\n",
        "                idf[j] = math.log(len(docs) / (n_containing_term))\n",
        "    print(tf)\n",
        "    print(idf)\n",
        "    # TFIDF matrix\n",
        "    tfidf = tf * idf\n",
        "    return tfidf"
      ],
      "metadata": {
        "id": "fMvCX0c6ZwOf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data['Text']"
      ],
      "metadata": {
        "id": "UfQQQ-5QbZIX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = compute_tf_idf(texts, ordered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5cEnjZobpsZ",
        "outputId": "d04922b4-33a0-4ddc-e356-c117d06f6370"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2        0.         0.2        ... 0.2        0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.05882353 0.         0.        ]]\n",
            "[1.44392347 2.61729584 1.80180981 2.65926004 2.60369019 2.24431618\n",
            " 2.88240359 3.05760768 2.71810054 3.05760768 2.79688141 2.57702194\n",
            " 2.28278247 2.81341072 2.71810054 2.67364877 2.02495336 1.69281952\n",
            " 1.98050159 3.07911388 3.01593498 2.67364877 2.90042209 2.76462055\n",
            " 2.84731227 2.79688141 2.71810054 2.67364877 3.14655516 2.16282315\n",
            " 2.79688141 2.61729584 1.84516025 2.44184716 2.70306266 2.88240359\n",
            " 2.3859667  2.37515579 2.11196473 2.93746337 2.68824757 3.41124772\n",
            " 1.29098418 3.07911388 3.38139475 2.78062089 2.97592965 3.01593498\n",
            " 2.70306266 2.79688141 2.39689577 2.46510402 2.97592965 2.3330443\n",
            " 3.35240722 2.29263476 3.14655516 3.77226106 3.54045945 3.32423634\n",
            " 1.94491065 2.43041846 1.72036947 0.57270103 2.12026354 2.47693848\n",
            " 2.93746337 2.51330612 2.30258509 2.73336801 2.08747371 2.02495336\n",
            " 2.71810054 1.96611286 3.44201938 3.19418321 2.91877123 2.17155683\n",
            " 3.72970145 3.07911388 3.29683737 2.95651156 2.51330612 2.73336801\n",
            " 1.98777435 3.47376807 3.54045945 3.44201938 2.18925641 2.56394986\n",
            " 4.07454193 3.57555077 2.51330612 2.59026717 3.12356565 3.17008566\n",
            " 3.24419363 3.19418321 3.27016912 2.60369019 2.70306266 3.07911388\n",
            " 3.61191841 2.91877123 2.45340798 2.07147337 1.23443201 3.12356565\n",
            " 3.35240722 3.03655427 3.19418321 2.60369019 3.57555077 2.46510402\n",
            " 2.59026717 1.60943791 2.60369019 2.91877123 1.86433016 2.67364877\n",
            " 2.3330443  1.80788885 2.93746337 1.82015894 2.04794287 2.73336801\n",
            " 1.88387476 2.29263476 2.47693848 3.03655427 3.14655516 3.07911388\n",
            " 2.50103603 4.60517019 3.12356565 2.91877123 2.65926004 2.59026717\n",
            " 2.78062089 3.24419363 2.90042209 3.41124772 2.71810054 2.47693848\n",
            " 2.17155683 2.01740615 3.47376807 3.07911388 2.86470401 4.34280592\n",
            " 3.01593498 2.59026717 3.5065579  1.98050159 2.39689577 1.62455155\n",
            " 1.99510039 3.54045945 2.28278247 3.9633163  3.21887582 2.79688141\n",
            " 2.99573227 2.57702194 2.81341072 2.34340709 2.93746337 3.29683737\n",
            " 2.57702194 3.24419363 2.3859667  3.12356565 3.14655516 2.61729584\n",
            " 2.40794561 2.52572864 3.07911388 2.23492644 2.97592965 1.89047544\n",
            " 3.35240722 2.28278247 2.81341072 3.38139475 3.35240722 1.95192822\n",
            " 2.88240359 3.19418321 2.81341072 3.27016912 2.7488722  1.82015894\n",
            " 3.81671283 2.41911891 2.03255796 2.53830743 2.6450754  3.41124772\n",
            " 3.17008566 2.95651156 1.30933332 3.29683737 2.65926004 2.83021784\n",
            " 2.56394986 3.14655516 2.65926004 2.59026717 1.48280526 2.81341072\n",
            " 2.81341072 2.39689577 2.65926004 2.43041846 2.17155683 3.07911388\n",
            " 2.56394986 2.83021784 2.93746337 2.60369019 2.59026717 3.47376807\n",
            " 2.48891467 3.19418321 3.17008566 1.73727128 3.14655516 2.18036746\n",
            " 2.88240359 3.61191841 2.99573227 1.93102154 0.93649344 2.67364877\n",
            " 1.56064775 2.95651156 2.93746337 2.40794561 2.19822508 2.95651156\n",
            " 3.01593498 3.17008566 2.34340709 3.03655427 2.6450754  1.70925825\n",
            " 2.79688141 2.18036746 2.81341072 2.60369019 2.97592965 3.10109279\n",
            " 2.43041846 1.53247687 3.64965874 2.03255796 3.35240722 3.12356565\n",
            " 3.17008566 2.91877123 2.41911891 2.19822508 1.93794198 3.10109279\n",
            " 2.86470401 3.32423634 2.6450754  3.54045945 2.81341072 3.19418321\n",
            " 2.34340709 2.6450754  2.55104645 3.03655427 2.88240359 2.73336801\n",
            " 1.98777435 2.6450754  2.08747371 2.93746337 3.14655516 2.07944154\n",
            " 2.67364877 2.56394986 2.6450754  1.95192822 2.84731227 3.68887945\n",
            " 2.83021784 3.35240722 2.90042209 2.84731227 2.51330612 2.79688141\n",
            " 3.03655427 3.03655427 3.64965874 2.70306266 2.6450754  3.35240722\n",
            " 2.14558134 3.57555077 2.10373423 2.23492644 2.73336801 2.3330443\n",
            " 2.3859667  2.95651156 2.40794561 2.57702194 2.78062089 2.65926004\n",
            " 2.23492644 3.21887582 3.17008566 2.84731227 3.14655516 1.48722028\n",
            " 3.35240722 2.16282315 2.55104645 2.59026717 2.93746337 2.99573227\n",
            " 2.99573227 3.27016912 2.99573227 2.13707065 2.01740615 1.64506509\n",
            " 2.43041846 2.53830743 2.23492644 2.97592965 3.10109279 2.99573227\n",
            " 3.05760768 2.93746337 2.20727491 2.78062089 1.41058705 2.81341072\n",
            " 3.05760768 2.93746337 3.10109279 3.14655516 1.77195684 2.6450754\n",
            " 2.23492644 2.40794561 2.6450754  2.60369019 2.14558134 3.10109279\n",
            " 3.27016912 2.68824757 2.71810054 2.40794561 2.93746337 2.60369019\n",
            " 2.99573227 3.21887582 3.57555077 2.99573227 2.52572864 2.08747371\n",
            " 3.05760768 2.05572502 2.02495336 2.95651156 2.50103603 2.06356819\n",
            " 3.35240722 2.99573227 1.551169   1.01335244 2.95651156 1.84516025\n",
            " 1.61948825 2.97592965 2.24431618 3.07911388 2.40794561 2.3227878\n",
            " 1.92414866 2.7488722  2.2164074  1.79576749 3.05760768 2.44184716\n",
            " 3.61191841 2.60369019 2.90042209 2.56394986 3.12356565 2.95651156\n",
            " 2.60369019 2.48891467 2.11196473 3.91202301 2.79688141 1.50058351\n",
            " 2.84731227 1.69826913 3.38139475 3.29683737 1.2039728  2.53830743\n",
            " 1.77785656 1.98777435 2.59026717 1.1776555  2.86470401 3.54045945\n",
            " 3.32423634 2.93746337 1.5702172  4.07454193 2.99573227 2.16282315\n",
            " 1.49610923 3.14655516 2.07147337 3.03655427 1.72597173 2.48891467\n",
            " 2.23492644 2.40794561 2.24431618 4.13516656 2.25379493 2.95651156\n",
            " 2.28278247 2.45340798 3.07911388 3.24419363 2.23492644 1.50959258\n",
            " 2.24431618 2.91877123 2.95651156 1.83258146 2.37515579 3.38139475\n",
            " 1.63989712 3.12356565 1.66600826 2.76462055 2.68824757 2.43041846\n",
            " 2.81341072 1.73160555 2.27302629 3.01593498 4.96184513 4.01738352\n",
            " 2.6450754  3.19418321 3.32423634 3.5065579  3.12356565 2.10373423\n",
            " 2.86470401 2.44184716 1.35479569 3.07911388 1.95192822 2.91877123\n",
            " 3.44201938 3.44201938 2.88240359 2.00991548 3.54045945 2.35387839\n",
            " 2.68824757 2.71810054 2.63108916 2.73336801 1.95899539 1.80180981\n",
            " 2.51330612 3.01593498 2.84731227 3.03655427 3.14655516 2.46510402\n",
            " 3.29683737 2.76462055 3.47376807 1.93102154 3.07911388 3.41124772\n",
            " 2.11196473 3.21887582 2.3644605  2.41911891 3.72970145 2.51330612\n",
            " 3.19418321 3.17008566 3.07911388 2.20727491 3.61191841 2.37515579\n",
            " 3.24419363 2.07147337 2.7488722  2.23492644 3.12356565 2.44184716\n",
            " 3.10109279 0.91879386 2.63108916 2.2164074  2.46510402 2.22562405\n",
            " 2.3227878  3.54045945 1.80788885 2.17155683 3.03655427 2.57702194\n",
            " 2.67364877 2.65926004 2.27302629 2.68824757 2.20727491 2.3644605\n",
            " 2.2164074  3.21887582 2.73336801 2.43041846 3.57555077 1.12701176\n",
            " 2.63108916 2.25379493 3.17008566 2.47693848 3.44201938 2.30258509\n",
            " 2.11196473 4.01738352 2.67364877 1.99510039 2.25379493 1.40649707\n",
            " 3.05760768 2.56394986 3.03655427 2.19822508 2.18036746 3.12356565\n",
            " 2.61729584 3.17008566 3.35240722 1.23787436 3.35240722 2.60369019\n",
            " 2.00991548 0.99425227 3.32423634 2.55104645 1.93102154 3.14655516\n",
            " 1.43548461 3.41124772 2.53830743 2.34340709 1.66073121 2.84731227\n",
            " 2.31263543 3.05760768 1.54646311 1.99510039 2.83021784 2.83021784\n",
            " 2.52572864 2.07944154 2.30258509 2.86470401 2.91877123 3.14655516\n",
            " 2.22562405 3.14655516 2.53830743 3.24419363 1.73160555 4.60517019\n",
            " 1.85150947 2.52572864 2.47693848 2.90042209 3.17008566 2.95651156\n",
            " 2.68824757 2.08747371 3.38139475 1.33560125 1.72597173 2.61729584\n",
            " 2.7488722  1.0300195  3.07911388 1.68200861 2.18036746 2.55104645\n",
            " 2.22562405 1.60943791 1.46967597 2.37515579 2.51330612 2.39689577\n",
            " 0.79186315 1.7837913  2.90042209 1.36649173 2.93746337 3.17008566\n",
            " 2.97592965 2.61729584 2.60369019 1.37436579 2.84731227 1.7837913\n",
            " 2.00991548 2.24431618 2.83021784 3.12356565 2.79688141 3.14655516\n",
            " 0.73188801 2.56394986 1.65025991 2.07147337 2.50103603 2.97592965\n",
            " 2.3330443  2.35387839 2.6450754  3.32423634 2.6450754  3.01593498\n",
            " 3.24419363 3.24419363 3.19418321 3.17008566 3.38139475 3.29683737\n",
            " 3.12356565 1.58963529 2.07147337 3.03655427 2.95651156 2.35387839\n",
            " 2.91877123 2.30258509 2.68824757 3.35240722 3.68887945 1.00512195\n",
            " 3.17008566 2.0024805  2.76462055 2.23492644 3.14655516 2.73336801\n",
            " 2.73336801 2.86470401 1.72597173 1.46533757 1.32425897 1.79576749\n",
            " 3.19418321 1.89047544 3.03655427 2.52572864 2.43041846 2.86470401\n",
            " 3.24419363 3.61191841 2.57702194 3.77226106 2.20727491 2.3330443\n",
            " 3.19418321 2.70306266 2.06356819 2.47693848 3.21887582 2.95651156\n",
            " 2.43041846 2.34340709 2.93746337 2.79688141 2.60369019 2.31263543\n",
            " 2.50103603 3.14655516 3.05760768 3.05760768 1.78976147 2.71810054\n",
            " 2.19822508 2.2164074  2.84731227 2.97592965 2.44184716 2.78062089\n",
            " 2.51330612 3.21887582 3.61191841 2.56394986 2.52572864 2.60369019\n",
            " 1.98777435 1.86433016 2.83021784 2.86470401 1.5945493  3.32423634\n",
            " 2.81341072 2.47693848 2.59026717 2.90042209 2.60369019 2.35387839\n",
            " 2.70306266 2.41911891 2.70306266 2.17155683 3.38139475 2.47693848\n",
            " 2.2164074  2.6450754  2.19822508 1.71479843 1.80180981 2.86470401\n",
            " 3.77226106 3.17008566 3.35240722 2.99573227 3.32423634 3.21887582\n",
            " 2.2164074  1.97328135 2.63108916 1.59948758 2.67364877 3.14655516\n",
            " 2.3859667  3.21887582 3.38139475 2.3859667  2.91877123 1.92414866\n",
            " 3.47376807 2.15416509 2.65926004 3.32423634 3.12356565 1.65025991\n",
            " 2.18036746 2.83021784 2.73336801 3.32423634 2.91877123 3.72970145\n",
            " 3.29683737 4.50986001 2.41911891 2.81341072 3.14655516 3.07911388\n",
            " 3.32423634 2.22562405 1.83885108 3.64965874 3.5065579  0.16605458\n",
            " 1.95899539 2.63108916 2.81341072 2.67364877 1.02722229 3.35240722\n",
            " 2.78062089 2.99573227 2.79688141 3.81671283 2.78062089 3.38139475\n",
            " 2.37515579 3.35240722 1.65025991 2.41911891 2.91877123 2.05572502\n",
            " 1.50959258 4.07454193 2.83021784 2.90042209 2.12863179 2.67364877\n",
            " 2.93746337 2.88240359 2.79688141 2.68824757 2.48891467 3.17008566\n",
            " 3.17008566 1.72597173 1.30563646 2.91877123 2.35387839 2.02495336\n",
            " 3.5065579  2.88240359 3.10109279 1.44392347 3.12356565 2.18925641\n",
            " 2.23492644 2.93746337 2.90042209 2.95651156 1.49610923 3.12356565\n",
            " 2.6450754  2.93746337 2.91877123 2.93746337 1.89047544 3.17008566\n",
            " 2.63108916 2.73336801 2.88240359 2.3859667  3.12356565 3.38139475\n",
            " 3.12356565 3.14655516 3.21887582 2.47693848 3.86323284 4.26869795\n",
            " 2.83021784 2.83021784 3.21887582 3.17008566 3.29683737 2.3859667\n",
            " 2.88240359 2.07147337 2.73336801 3.44201938 2.65926004 2.73336801\n",
            " 2.88240359 2.05572502 1.5702172  2.07944154 2.3330443  3.54045945\n",
            " 2.83021784 2.47693848 1.54177926 2.95651156 2.57702194 3.17008566\n",
            " 2.95651156 2.76462055 2.34340709 2.84731227 3.9633163  3.17008566\n",
            " 3.57555077 2.12863179 2.81341072 2.12863179 2.79688141 2.39689577\n",
            " 1.91732269 2.83021784 2.93746337 3.19418321 2.25379493 3.07911388\n",
            " 1.04696906 2.29263476 2.19822508 2.37515579 2.7488722  2.17155683\n",
            " 2.18925641 3.01593498 3.05760768 2.63108916 3.57555077 2.67364877\n",
            " 3.91202301 2.00991548 1.73160555 1.95192822 2.70306266 2.25379493\n",
            " 3.05760768 3.14655516 1.34323487 2.63108916 0.93394567 2.37515579\n",
            " 2.81341072 2.78062089 1.3130439  2.45340798 2.01740615 3.47376807\n",
            " 1.76609172 2.50103603 2.28278247 3.01593498 3.05760768 2.84731227\n",
            " 2.23492644 2.91877123 3.07911388 1.7602608  2.93746337 3.38139475\n",
            " 3.57555077 2.43041846 2.07944154 2.37515579 1.00512195 1.41058705\n",
            " 4.96184513 3.07911388 2.70306266 2.22562405 2.90042209 3.12356565\n",
            " 3.05760768 0.99967234 1.1874435  2.47693848 4.42284863 2.78062089\n",
            " 2.81341072 3.07911388 3.29683737 2.7488722  2.68824757 2.65926004\n",
            " 3.77226106 3.05760768 2.43041846 3.10109279 4.60517019 3.05760768\n",
            " 2.70306266 1.33560125 2.84731227 2.16282315 2.71810054 1.39836694\n",
            " 2.97592965 2.17155683 2.51330612 1.37436579 2.88240359 1.42711636\n",
            " 2.20727491 3.19418321 2.35387839 2.7488722  3.03655427 2.47693848\n",
            " 2.86470401 1.50959258 3.32423634 2.65926004 2.50103603 2.18036746\n",
            " 3.03655427 3.14655516 1.30195321 3.29683737 1.20731171 2.81341072\n",
            " 3.14655516 0.68716511 3.24419363 3.03655427 0.52593926 2.25379493\n",
            " 2.7488722  2.57702194 4.50986001 3.86323284]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df = pd.DataFrame(tfidf_matrix, columns=list(ordered_words))\n",
        "top_freq_words = {}\n",
        "top_tfidf_words = {}"
      ],
      "metadata": {
        "id": "gBa_9PGgbr1E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in data['Category'].unique():\n",
        "    category_data = data[data['Category'] == category]\n",
        "    category_indices = category_data.index\n",
        "    category_texts = category_data['Text']\n",
        "\n",
        "    # Computing the most frequent words\n",
        "    all_words = []\n",
        "    for text in category_texts:\n",
        "        all_words.extend(get_tokens(text))\n",
        "    word_counts = Counter(all_words)\n",
        "    top_freq_words[category] = word_counts.most_common(3)\n",
        "\n",
        "    # Computing the highest average TFIDF words\n",
        "\n",
        "    category_tfidf = tfidf_df.loc[category_indices].mean().sort_values(ascending=False)\n",
        "    top_tfidf_words_with_scores = category_tfidf.head(3)\n",
        "    top_tfidf_words[category] = {word: score for word, score in top_tfidf_words_with_scores.items()}\n"
      ],
      "metadata": {
        "id": "ndMaH8TYcu77"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 3 Most Frequent Words in Each Category:\", top_freq_words)\n",
        "print(\"Top 3 Highest Average TFIDF Words in Each Category:\", top_tfidf_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaVv7A2sc37V",
        "outputId": "7473d9b3-e431-464a-f2ac-586cc9bf81c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Most Frequent Words in Each Category: {'sport': [('said', 428), ('game', 353), ('win', 288)], 'business': [('said', 724), ('us', 377), ('year', 360)], 'tech': [('said', 757), ('use', 459), ('peopl', 427)], 'entertainment': [('film', 450), ('said', 386), ('year', 249)], 'politics': [('said', 996), ('mr', 726), ('would', 495)]}\n",
            "Top 3 Highest Average TFIDF Words in Each Category: {'sport': {'game': 0.35727414648708805, 'england': 0.31907434737608514, 'win': 0.30741067997068455}, 'business': {'firm': 0.2891252868078186, 'bank': 0.2697288199539767, 'market': 0.2616290834155383}, 'tech': {'mobil': 0.3462714837303001, 'phone': 0.3319065027131584, 'softwar': 0.3152238172837377}, 'entertainment': {'film': 0.7216412939111394, 'award': 0.4106447057087541, 'star': 0.40803563438879187}, 'politics': {'labour': 0.45105036714182084, 'elect': 0.4313731783204545, 'mr': 0.42043597469422206}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df.to_csv('tfidf_matrix.csv', index=False)"
      ],
      "metadata": {
        "id": "-1wAJDyodHvv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONVERTING THE TFIDF MATRIX TO A TEXT FILE ('matrix.txt')\n",
        "matrix_string = \"\\n\".join(\",\".join(map(str, row)) for row in tfidf_matrix)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/matrix.txt'\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(matrix_string)\n",
        "\n",
        "file_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0-8bKIa_dpnf",
        "outputId": "0568eb04-1260-483e-8237-107034abdf58"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/matrix.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CONVERTING THE MAP TO A JSON FILE - TOP 3 FREQUENT WORDS IN EACH CATEGORY (frequenxy.json)\n",
        "\n",
        "for key in top_freq_words:\n",
        "    top_freq_words[key] = [list(item) for item in top_freq_words[key]]\n",
        "\n",
        "adjusted_map = {}\n",
        "for category, words in top_freq_words.items():\n",
        "    adjusted_map[category] = {word: freq for word, freq in words}\n",
        "\n",
        "json_file_path = '/content/drive/MyDrive/frequency.json'\n",
        "\n",
        "with open(json_file_path, 'w') as json_file:\n",
        "    json.dump(adjusted_map, json_file, indent=4)\n",
        "\n",
        "print(f\"File saved at {json_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYq99aPGeVZW",
        "outputId": "1d891337-15f9-45ff-cb60-139eed2ff091"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved at /content/drive/MyDrive/frequency.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CONVERTING THE MAP TO A JSON FILE - top 3 highest average TFIDF words by category (scores.json)\n",
        "\n",
        "json_file_path = '/content/drive/MyDrive/scores.json'\n",
        "\n",
        "with open(json_file_path, 'w') as json_file:\n",
        "    json.dump(top_tfidf_words, json_file, indent=4)\n",
        "\n",
        "print(f\"File saved at {json_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2H2MBjpgGi-",
        "outputId": "f66d9827-f897-41a7-d330-b191c55d6386"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved at /content/drive/MyDrive/scores.json\n"
          ]
        }
      ]
    }
  ]
}